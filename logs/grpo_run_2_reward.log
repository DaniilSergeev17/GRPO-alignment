ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 07-13 14:54:23 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 07-13 14:54:23 [__init__.py:239] Automatically detected platform cuda.
==((====))==  Unsloth 2025.7.3: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.8.5.post1.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 4. Max memory: 79.254 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: vLLM loading Qwen2.5-0.5B-Instruct with actual GPU utilization = 47.22%
Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 79.25 GB.
Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 320.
Unsloth: vLLM's KV Cache can use up to 36.44 GB. Also swap space = 6 GB.
WARNING 07-13 14:59:15 [config.py:2972] Casting torch.bfloat16 to torch.float16.
INFO 07-13 14:59:23 [config.py:717] This model supports multiple tasks: {'score', 'classify', 'embed', 'reward', 'generate'}. Defaulting to 'generate'.
INFO 07-13 14:59:23 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=1024.
Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'fp4', 'bnb_4bit_use_double_quant': False, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': [], 'llm_int8_threshold': 6.0}
INFO 07-13 14:59:24 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"backend":"inductor","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"debug":false,"dce":true,"coordinate_descent_tuning":true,"trace.enabled":false,"trace.graph_diagram":false,"triton.cudagraphs":true,"compile_threads":48,"max_autotune":false,"disable_progress":false,"verbose_progress":true,"enable_auto_functionalized_v2":false},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 07-13 14:59:24 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f60bd7492d0>
INFO 07-13 14:59:35 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-13 14:59:35 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 07-13 14:59:35 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 07-13 14:59:35 [gpu_model_runner.py:1329] Starting to load model Qwen2.5-0.5B-Instruct...
INFO 07-13 14:59:35 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.16it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.16it/s]

INFO 07-13 14:59:35 [punica_selector.py:18] Using PunicaWrapperGPU.
INFO 07-13 14:59:36 [gpu_model_runner.py:1347] Model loading took 0.4999 GiB and 0.525208 seconds
INFO 07-13 14:59:50 [backends.py:420] Using cache directory: /home/sergeev/.cache/vllm/torch_compile_cache/3dfe22fce5/rank_0_0 for vLLM's torch.compile
INFO 07-13 14:59:50 [backends.py:430] Dynamo bytecode transform time: 12.57 s
INFO 07-13 14:59:58 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 6.986 s
INFO 07-13 15:00:01 [monitor.py:33] torch.compile takes 12.57 s in total
INFO 07-13 15:00:01 [kv_cache_utils.py:634] GPU KV cache size: 2,678,992 tokens
INFO 07-13 15:00:01 [kv_cache_utils.py:637] Maximum concurrency for 1,024 tokens per request: 2616.20x
INFO 07-13 15:04:59 [gpu_model_runner.py:1686] Graph capturing finished in 298 secs, took 1.05 GiB
INFO 07-13 15:05:01 [core.py:159] init engine (profile, create kv cache, warmup model) took 325.68 seconds
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm', 'k_norm', 'q_norm']
Unsloth: Just some info: will skip parsing ['pre_feedforward_layernorm', 'post_feedforward_layernorm', 'k_norm', 'q_norm']
Unsloth 2025.7.3 patched 24 layers with 24 QKV layers, 24 O layers and 24 MLP layers.
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 2 to the `num_generations` of 8
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 234
O^O/ \_/ \    Batch size per device = 32 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (32 x 8 x 1) = 256
 "-____-"     Trainable parameters = 35,192,832 of 529,225,600 (6.65% trained)
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 0.0002248813398182392, 'learning_rate': 1.8750000000000003e-06, 'num_tokens': 885886.0, 'completions/mean_length': 244.22421875, 'completions/min_length': 10.2, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.1171875, 'completions/mean_terminated_length': 209.33021850585936, 'completions/min_terminated_length': 10.2, 'completions/max_terminated_length': 507.0, 'rewards/strict_format_reward_func/mean': 0.004296875, 'rewards/strict_format_reward_func/std': 0.05403594672679901, 'rewards/exact_match_reward_func/mean': 0.000390625, 'rewards/exact_match_reward_func/std': 0.00625, 'reward': 0.0046875, 'reward_std': 0.013258251827210188, 'frac_reward_zero_std': 0.9625, 'completion_length': 244.22421875, 'kl': 2.059807211480802e-05, 'epoch': 0.04}
{'loss': 0.0, 'grad_norm': 1.165249228477478, 'learning_rate': 3.958333333333333e-06, 'num_tokens': 1752955.0, 'completions/mean_length': 240.598828125, 'completions/min_length': 12.9, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.121875, 'completions/mean_terminated_length': 203.9476058959961, 'completions/min_terminated_length': 12.9, 'completions/max_terminated_length': 504.9, 'rewards/strict_format_reward_func/mean': 0.0078125, 'rewards/strict_format_reward_func/std': 0.08177776411175727, 'rewards/exact_match_reward_func/mean': 0.001171875, 'rewards/exact_match_reward_func/std': 0.01875, 'reward': 0.008984375, 'reward_std': 0.023885419964790343, 'frac_reward_zero_std': 0.9375, 'completion_length': 240.598828125, 'kl': 0.0002755814003194246, 'epoch': 0.09}
{'loss': 0.0, 'grad_norm': 1.8886877298355103, 'learning_rate': 4.993009492952951e-06, 'num_tokens': 2605677.0, 'completions/mean_length': 232.01953125, 'completions/min_length': 12.3, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.0953125, 'completions/mean_terminated_length': 202.7086441040039, 'completions/min_terminated_length': 12.3, 'completions/max_terminated_length': 499.4, 'rewards/strict_format_reward_func/mean': 0.034375, 'rewards/strict_format_reward_func/std': 0.17321353927254676, 'rewards/exact_match_reward_func/mean': 0.004296875, 'rewards/exact_match_reward_func/std': 0.05403594672679901, 'reward': 0.038671875, 'reward_std': 0.09407972414046525, 'frac_reward_zero_std': 0.778125, 'completion_length': 232.01953125, 'kl': 0.004206300649093464, 'epoch': 0.13}
{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 4.937319780454559e-06, 'num_tokens': 3387936.0, 'completions/mean_length': 206.669921875, 'completions/min_length': 12.5, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.063671875, 'completions/mean_terminated_length': 186.25899505615234, 'completions/min_terminated_length': 12.5, 'completions/max_terminated_length': 499.4, 'rewards/strict_format_reward_func/mean': 0.167578125, 'rewards/strict_format_reward_func/std': 0.36236083805561065, 'rewards/exact_match_reward_func/mean': 0.01328125, 'rewards/exact_match_reward_func/std': 0.09143321216106415, 'reward': 0.180859375, 'reward_std': 0.32223999351263044, 'frac_reward_zero_std': 0.296875, 'completion_length': 206.669921875, 'kl': 0.0403715681633912, 'epoch': 0.17}
{'loss': 0.0001, 'grad_norm': 4.0421600341796875, 'learning_rate': 4.8405871765993435e-06, 'num_tokens': 4112977.0, 'completions/mean_length': 182.931640625, 'completions/min_length': 18.6, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.04765625, 'completions/mean_terminated_length': 166.7527847290039, 'completions/min_terminated_length': 18.6, 'completions/max_terminated_length': 498.5, 'rewards/strict_format_reward_func/mean': 0.49140625, 'rewards/strict_format_reward_func/std': 0.4882956683635712, 'rewards/exact_match_reward_func/mean': 0.0375, 'rewards/exact_match_reward_func/std': 0.17757207229733468, 'reward': 0.52890625, 'reward_std': 0.5122822731733322, 'frac_reward_zero_std': 0.034375, 'completion_length': 182.931640625, 'kl': 0.09685046840459108, 'epoch': 0.21}
{'loss': 0.4523, 'grad_norm': 3.83736515045166, 'learning_rate': 4.701488829641845e-06, 'num_tokens': 4788044.0, 'completions/mean_length': 155.810546875, 'completions/min_length': 21.6, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.015625, 'completions/mean_terminated_length': 150.35082931518554, 'completions/min_terminated_length': 21.6, 'completions/max_terminated_length': 492.2, 'rewards/strict_format_reward_func/mean': 0.7828125, 'rewards/strict_format_reward_func/std': 0.4054361343383789, 'rewards/exact_match_reward_func/mean': 0.062109375, 'rewards/exact_match_reward_func/std': 0.21346758902072907, 'reward': 0.844921875, 'reward_std': 0.41135340332984927, 'frac_reward_zero_std': 0.140625, 'completion_length': 155.810546875, 'kl': 452.26933848783375, 'epoch': 0.26}
{'loss': 0.0005, 'grad_norm': 3.5965447425842285, 'learning_rate': 4.500333870028017e-06, 'num_tokens': 5374468.0, 'completions/mean_length': 129.459375, 'completions/min_length': 26.7, 'completions/max_length': 493.3, 'completions/clipped_ratio': 0.006640625, 'completions/mean_terminated_length': 126.9580322265625, 'completions/min_terminated_length': 26.7, 'completions/max_terminated_length': 447.1, 'rewards/strict_format_reward_func/mean': 0.915234375, 'rewards/strict_format_reward_func/std': 0.27636556178331373, 'rewards/exact_match_reward_func/mean': 0.084765625, 'rewards/exact_match_reward_func/std': 0.26550241857767104, 'reward': 1.0, 'reward_std': 0.30440170764923097, 'frac_reward_zero_std': 0.309375, 'completion_length': 129.459375, 'kl': 0.4676974546164274, 'epoch': 0.3}
{'loss': 0.0021, 'grad_norm': nan, 'learning_rate': 4.2544947572099795e-06, 'num_tokens': 5922313.0, 'completions/mean_length': 113.864453125, 'completions/min_length': 26.7, 'completions/max_length': 446.1, 'completions/clipped_ratio': 0.00390625, 'completions/mean_terminated_length': 112.39744644165039, 'completions/min_terminated_length': 26.7, 'completions/max_terminated_length': 406.4, 'rewards/strict_format_reward_func/mean': 0.9515625, 'rewards/strict_format_reward_func/std': 0.21260233968496323, 'rewards/exact_match_reward_func/mean': 0.127734375, 'rewards/exact_match_reward_func/std': 0.31138907223939893, 'reward': 1.079296875, 'reward_std': 0.27036500424146653, 'frac_reward_zero_std': 0.415625, 'completion_length': 113.864453125, 'kl': 2.0841520024463533, 'epoch': 0.34}
{'loss': 0.0023, 'grad_norm': 21.864688873291016, 'learning_rate': 3.999554736719785e-06, 'num_tokens': 6504052.0, 'completions/mean_length': 122.516796875, 'completions/min_length': 28.8, 'completions/max_length': 455.1, 'completions/clipped_ratio': 0.003515625, 'completions/mean_terminated_length': 121.14954452514648, 'completions/min_terminated_length': 28.8, 'completions/max_terminated_length': 404.7, 'rewards/strict_format_reward_func/mean': 0.956640625, 'rewards/strict_format_reward_func/std': 0.20145692080259323, 'rewards/exact_match_reward_func/mean': 0.1578125, 'rewards/exact_match_reward_func/std': 0.35661655366420747, 'reward': 1.114453125, 'reward_std': 0.2864028111100197, 'frac_reward_zero_std': 0.36875, 'completion_length': 122.516796875, 'kl': 2.276572554372251, 'epoch': 0.39}
{'loss': 0.0016, 'grad_norm': 2.541266679763794, 'learning_rate': 3.684671656182497e-06, 'num_tokens': 7069871.0, 'completions/mean_length': 120.560546875, 'completions/min_length': 26.7, 'completions/max_length': 483.3, 'completions/clipped_ratio': 0.005078125, 'completions/mean_terminated_length': 118.6290771484375, 'completions/min_terminated_length': 26.7, 'completions/max_terminated_length': 415.1, 'rewards/strict_format_reward_func/mean': 0.97421875, 'rewards/strict_format_reward_func/std': 0.1540766939520836, 'rewards/exact_match_reward_func/mean': 0.1375, 'rewards/exact_match_reward_func/std': 0.32592189610004424, 'reward': 1.11171875, 'reward_std': 0.24306090623140336, 'frac_reward_zero_std': 0.44375, 'completion_length': 120.560546875, 'kl': 1.5645646441727876, 'epoch': 0.43}
{'loss': 0.0006, 'grad_norm': 6.245366096496582, 'learning_rate': 3.3433249684570757e-06, 'num_tokens': 7648774.0, 'completions/mean_length': 123.096484375, 'completions/min_length': 28.5, 'completions/max_length': 487.3, 'completions/clipped_ratio': 0.002734375, 'completions/mean_terminated_length': 122.03523254394531, 'completions/min_terminated_length': 28.5, 'completions/max_terminated_length': 439.9, 'rewards/strict_format_reward_func/mean': 0.974609375, 'rewards/strict_format_reward_func/std': 0.15260138660669326, 'rewards/exact_match_reward_func/mean': 0.14453125, 'rewards/exact_match_reward_func/std': 0.3439517542719841, 'reward': 1.119140625, 'reward_std': 0.25049048066139223, 'frac_reward_zero_std': 0.41875, 'completion_length': 123.096484375, 'kl': 0.5638363605365158, 'epoch': 0.47}
{'loss': 0.0013, 'grad_norm': 2.643167495727539, 'learning_rate': 2.9831397944888833e-06, 'num_tokens': 8224640.0, 'completions/mean_length': 120.12265625, 'completions/min_length': 30.7, 'completions/max_length': 425.9, 'completions/clipped_ratio': 0.003515625, 'completions/mean_terminated_length': 118.85574569702149, 'completions/min_terminated_length': 30.7, 'completions/max_terminated_length': 410.1, 'rewards/strict_format_reward_func/mean': 0.979296875, 'rewards/strict_format_reward_func/std': 0.13635785952210427, 'rewards/exact_match_reward_func/mean': 0.126171875, 'rewards/exact_match_reward_func/std': 0.31575655192136765, 'reward': 1.10546875, 'reward_std': 0.22060322910547256, 'frac_reward_zero_std': 0.48125, 'completion_length': 120.12265625, 'kl': 1.278032645955682, 'epoch': 0.51}
{'loss': 0.001, 'grad_norm': 4.537477016448975, 'learning_rate': 2.6121620758762877e-06, 'num_tokens': 8785112.0, 'completions/mean_length': 117.484375, 'completions/min_length': 25.6, 'completions/max_length': 473.8, 'completions/clipped_ratio': 0.0046875, 'completions/mean_terminated_length': 115.74847412109375, 'completions/min_terminated_length': 25.6, 'completions/max_terminated_length': 417.9, 'rewards/strict_format_reward_func/mean': 0.978515625, 'rewards/strict_format_reward_func/std': 0.1405813455581665, 'rewards/exact_match_reward_func/mean': 0.15390625, 'rewards/exact_match_reward_func/std': 0.3391741424798965, 'reward': 1.132421875, 'reward_std': 0.22715192064642906, 'frac_reward_zero_std': 0.484375, 'completion_length': 117.484375, 'kl': 1.0353550879284739, 'epoch': 0.56}
{'loss': 0.0006, 'grad_norm': 2.24552321434021, 'learning_rate': 2.238678841830867e-06, 'num_tokens': 9365492.0, 'completions/mean_length': 122.0234375, 'completions/min_length': 29.1, 'completions/max_length': 460.5, 'completions/clipped_ratio': 0.0046875, 'completions/mean_terminated_length': 120.24544067382813, 'completions/min_terminated_length': 29.1, 'completions/max_terminated_length': 405.4, 'rewards/strict_format_reward_func/mean': 0.979296875, 'rewards/strict_format_reward_func/std': 0.14054245874285698, 'rewards/exact_match_reward_func/mean': 0.11640625, 'rewards/exact_match_reward_func/std': 0.3172807902097702, 'reward': 1.095703125, 'reward_std': 0.19472731053829193, 'frac_reward_zero_std': 0.546875, 'completion_length': 122.0234375, 'kl': 0.6281097691506148, 'epoch': 0.6}
{'loss': 0.0012, 'grad_norm': 5.646249294281006, 'learning_rate': 1.9072990557112567e-06, 'num_tokens': 9933704.0, 'completions/mean_length': 117.7078125, 'completions/min_length': 27.0, 'completions/max_length': 477.7, 'completions/clipped_ratio': 0.002734375, 'completions/mean_terminated_length': 116.64390258789062, 'completions/min_terminated_length': 27.0, 'completions/max_terminated_length': 415.7, 'rewards/strict_format_reward_func/mean': 0.985546875, 'rewards/strict_format_reward_func/std': 0.10952542200684548, 'rewards/exact_match_reward_func/mean': 0.1546875, 'rewards/exact_match_reward_func/std': 0.3432218089699745, 'reward': 1.140234375, 'reward_std': 0.23092031478881836, 'frac_reward_zero_std': 0.484375, 'completion_length': 117.7078125, 'kl': 1.234201624058187, 'epoch': 0.64}
{'loss': 0.0009, 'grad_norm': 3.4660511016845703, 'learning_rate': 1.5519363433676794e-06, 'num_tokens': 10473699.0, 'completions/mean_length': 112.210546875, 'completions/min_length': 29.1, 'completions/max_length': 470.8, 'completions/clipped_ratio': 0.002734375, 'completions/mean_terminated_length': 111.19621505737305, 'completions/min_terminated_length': 29.1, 'completions/max_terminated_length': 465.1, 'rewards/strict_format_reward_func/mean': 0.97890625, 'rewards/strict_format_reward_func/std': 0.13682002127170562, 'rewards/exact_match_reward_func/mean': 0.166796875, 'rewards/exact_match_reward_func/std': 0.365949758887291, 'reward': 1.145703125, 'reward_std': 0.26372868567705154, 'frac_reward_zero_std': 0.40625, 'completion_length': 112.210546875, 'kl': 0.8964762132614851, 'epoch': 0.68}
{'loss': 0.0012, 'grad_norm': 3.958406925201416, 'learning_rate': 1.217751806485235e-06, 'num_tokens': 11048382.0, 'completions/mean_length': 122.098046875, 'completions/min_length': 29.3, 'completions/max_length': 477.5, 'completions/clipped_ratio': 0.005859375, 'completions/mean_terminated_length': 119.85968399047852, 'completions/min_terminated_length': 29.3, 'completions/max_terminated_length': 414.7, 'rewards/strict_format_reward_func/mean': 0.979296875, 'rewards/strict_format_reward_func/std': 0.130745629966259, 'rewards/exact_match_reward_func/mean': 0.1640625, 'rewards/exact_match_reward_func/std': 0.34418890327215196, 'reward': 1.143359375, 'reward_std': 0.23075381964445113, 'frac_reward_zero_std': 0.471875, 'completion_length': 122.098046875, 'kl': 1.2418777335435152, 'epoch': 0.73}
{'loss': 0.0017, 'grad_norm': 4.202700614929199, 'learning_rate': 9.122105753945532e-07, 'num_tokens': 11611102.0, 'completions/mean_length': 119.95, 'completions/min_length': 26.7, 'completions/max_length': 453.2, 'completions/clipped_ratio': 0.005078125, 'completions/mean_terminated_length': 117.96945343017578, 'completions/min_terminated_length': 26.7, 'completions/max_terminated_length': 387.5, 'rewards/strict_format_reward_func/mean': 0.978125, 'rewards/strict_format_reward_func/std': 0.1440718874335289, 'rewards/exact_match_reward_func/mean': 0.171875, 'rewards/exact_match_reward_func/std': 0.36584393233060836, 'reward': 1.15, 'reward_std': 0.24631463289260863, 'frac_reward_zero_std': 0.425, 'completion_length': 119.95, 'kl': 1.6512539306655527, 'epoch': 0.77}
{'loss': 0.0008, 'grad_norm': 4.666375160217285, 'learning_rate': 6.421379363065142e-07, 'num_tokens': 12178446.0, 'completions/mean_length': 118.26875, 'completions/min_length': 24.4, 'completions/max_length': 429.2, 'completions/clipped_ratio': 0.001953125, 'completions/mean_terminated_length': 117.49401245117187, 'completions/min_terminated_length': 24.4, 'completions/max_terminated_length': 388.3, 'rewards/strict_format_reward_func/mean': 0.9859375, 'rewards/strict_format_reward_func/std': 0.11649828180670738, 'rewards/exact_match_reward_func/mean': 0.13984375, 'rewards/exact_match_reward_func/std': 0.33864211440086367, 'reward': 1.12578125, 'reward_std': 0.23083995431661605, 'frac_reward_zero_std': 0.446875, 'completion_length': 118.26875, 'kl': 0.8322166740894318, 'epoch': 0.81}
{'loss': 0.0015, 'grad_norm': 4.243305683135986, 'learning_rate': 4.1356686569674344e-07, 'num_tokens': 12746377.0, 'completions/mean_length': 118.485546875, 'completions/min_length': 29.8, 'completions/max_length': 441.7, 'completions/clipped_ratio': 0.004296875, 'completions/mean_terminated_length': 116.81824951171875, 'completions/min_terminated_length': 29.8, 'completions/max_terminated_length': 380.2, 'rewards/strict_format_reward_func/mean': 0.983984375, 'rewards/strict_format_reward_func/std': 0.12166176661849022, 'rewards/exact_match_reward_func/mean': 0.165234375, 'rewards/exact_match_reward_func/std': 0.3530130609869957, 'reward': 1.14921875, 'reward_std': 0.2332553409039974, 'frac_reward_zero_std': 0.46875, 'completion_length': 118.485546875, 'kl': 1.4675127217546104, 'epoch': 0.86}
{'loss': 0.0011, 'grad_norm': 2.329836845397949, 'learning_rate': 2.316032635803378e-07, 'num_tokens': 13307622.0, 'completions/mean_length': 117.523828125, 'completions/min_length': 30.1, 'completions/max_length': 440.2, 'completions/clipped_ratio': 0.003515625, 'completions/mean_terminated_length': 116.13610458374023, 'completions/min_terminated_length': 30.1, 'completions/max_terminated_length': 367.7, 'rewards/strict_format_reward_func/mean': 0.985546875, 'rewards/strict_format_reward_func/std': 0.11732721850275993, 'rewards/exact_match_reward_func/mean': 0.18125, 'rewards/exact_match_reward_func/std': 0.3706101685762405, 'reward': 1.166796875, 'reward_std': 0.26045015901327134, 'frac_reward_zero_std': 0.4125, 'completion_length': 117.523828125, 'kl': 1.1007033292204143, 'epoch': 0.9}
{'loss': 0.0008, 'grad_norm': 8.924843788146973, 'learning_rate': 1.0031189614277765e-07, 'num_tokens': 13872408.0, 'completions/mean_length': 122.14453125, 'completions/min_length': 31.5, 'completions/max_length': 474.0, 'completions/clipped_ratio': 0.00390625, 'completions/mean_terminated_length': 120.6151252746582, 'completions/min_terminated_length': 31.5, 'completions/max_terminated_length': 407.8, 'rewards/strict_format_reward_func/mean': 0.983203125, 'rewards/strict_format_reward_func/std': 0.12443550229072571, 'rewards/exact_match_reward_func/mean': 0.113671875, 'rewards/exact_match_reward_func/std': 0.30813458263874055, 'reward': 1.096875, 'reward_std': 0.20081241130828859, 'frac_reward_zero_std': 0.521875, 'completion_length': 122.14453125, 'kl': 0.785663160867989, 'epoch': 0.94}
{'loss': 0.0012, 'grad_norm': 3.344409227371216, 'learning_rate': 2.262559558016325e-08, 'num_tokens': 14435123.0, 'completions/mean_length': 117.298046875, 'completions/min_length': 33.7, 'completions/max_length': 406.6, 'completions/clipped_ratio': 0.002734375, 'completions/mean_terminated_length': 116.24336166381836, 'completions/min_terminated_length': 33.7, 'completions/max_terminated_length': 389.6, 'rewards/strict_format_reward_func/mean': 0.98515625, 'rewards/strict_format_reward_func/std': 0.11520239636301995, 'rewards/exact_match_reward_func/mean': 0.202734375, 'rewards/exact_match_reward_func/std': 0.3899538114666939, 'reward': 1.187890625, 'reward_std': 0.2685036689043045, 'frac_reward_zero_std': 0.4, 'completion_length': 117.298046875, 'kl': 1.2078978843986987, 'epoch': 0.98}
{'train_runtime': 5557.865, 'train_samples_per_second': 1.345, 'train_steps_per_second': 0.042, 'train_loss': 0.020428983706009454, 'num_tokens': 14661615.0, 'completions/mean_length': 113.33984375, 'completions/min_length': 30.75, 'completions/max_length': 451.25, 'completions/clipped_ratio': 0.001953125, 'completions/mean_terminated_length': 112.66302871704102, 'completions/min_terminated_length': 30.75, 'completions/max_terminated_length': 436.75, 'rewards/strict_format_reward_func/mean': 0.990234375, 'rewards/strict_format_reward_func/std': 0.09802134335041046, 'rewards/exact_match_reward_func/mean': 0.1826171875, 'rewards/exact_match_reward_func/std': 0.3795386850833893, 'reward': 1.1728515625, 'reward_std': 0.2677897736430168, 'frac_reward_zero_std': 0.40625, 'completion_length': 112.734375, 'kl': 1.20591173853193, 'epoch': 1.0}

after GRPO: Accuracy -> 0.2312357846853677, Right format percent -> 0.9893858984078847