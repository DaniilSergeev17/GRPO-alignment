ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
INFO 07-13 22:30:50 [importing.py:53] Triton module has been replaced with a placeholder.
INFO 07-13 22:30:50 [__init__.py:239] Automatically detected platform cuda.
==((====))==  Unsloth 2025.7.3: Fast Qwen2 patching. Transformers: 4.53.2. vLLM: 0.8.5.post1.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 4. Max memory: 79.254 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth: vLLM loading Qwen2.5-0.5B-Instruct with actual GPU utilization = 47.22%
Unsloth: Your GPU has CUDA compute capability 8.0 with VRAM = 79.25 GB.
Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 320.
Unsloth: vLLM's KV Cache can use up to 36.44 GB. Also swap space = 6 GB.
WARNING 07-13 22:35:43 [config.py:2972] Casting torch.bfloat16 to torch.float16.
INFO 07-13 22:35:51 [config.py:717] This model supports multiple tasks: {'generate', 'embed', 'reward', 'score', 'classify'}. Defaulting to 'generate'.
INFO 07-13 22:35:51 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=1024.
Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'fp4', 'bnb_4bit_use_double_quant': False, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': [], 'llm_int8_threshold': 6.0}
INFO 07-13 22:35:51 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"backend":"inductor","custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"debug":false,"dce":true,"coordinate_descent_tuning":true,"trace.enabled":false,"trace.graph_diagram":false,"triton.cudagraphs":true,"compile_threads":48,"max_autotune":false,"disable_progress":false,"verbose_progress":true,"enable_auto_functionalized_v2":false},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 07-13 22:35:51 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fa6d53e0690>
INFO 07-13 22:36:02 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 07-13 22:36:02 [cuda.py:221] Using Flash Attention backend on V1 engine.
WARNING 07-13 22:36:02 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
INFO 07-13 22:36:02 [gpu_model_runner.py:1329] Starting to load model Qwen2.5-0.5B-Instruct...
INFO 07-13 22:36:02 [loader.py:1187] Loading weights with BitsAndBytes quantization. May take a while ...
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.55it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.55it/s]

INFO 07-13 22:36:02 [punica_selector.py:18] Using PunicaWrapperGPU.
INFO 07-13 22:36:03 [gpu_model_runner.py:1347] Model loading took 0.4999 GiB and 0.571835 seconds
INFO 07-13 22:36:17 [backends.py:420] Using cache directory: /home/sergeev/.cache/vllm/torch_compile_cache/3dfe22fce5/rank_0_0 for vLLM's torch.compile
INFO 07-13 22:36:17 [backends.py:430] Dynamo bytecode transform time: 12.08 s
INFO 07-13 22:36:24 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 6.711 s
INFO 07-13 22:36:27 [monitor.py:33] torch.compile takes 12.08 s in total
INFO 07-13 22:36:28 [kv_cache_utils.py:634] GPU KV cache size: 2,678,992 tokens
INFO 07-13 22:36:28 [kv_cache_utils.py:637] Maximum concurrency for 1,024 tokens per request: 2616.20x
INFO 07-13 22:41:28 [gpu_model_runner.py:1686] Graph capturing finished in 300 secs, took 1.05 GiB
INFO 07-13 22:41:30 [core.py:159] init engine (profile, create kv cache, warmup model) took 327.34 seconds
Unsloth: Just some info: will skip parsing ['q_norm', 'pre_feedforward_layernorm', 'k_norm', 'post_feedforward_layernorm']
Unsloth: Just some info: will skip parsing ['q_norm', 'pre_feedforward_layernorm', 'k_norm', 'post_feedforward_layernorm']
Unsloth 2025.7.3 patched 24 layers with 24 QKV layers, 24 O layers and 24 MLP layers.
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7473/7473 [00:00<00:00, 22411.18 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1319/1319 [00:00<00:00, 20694.29 examples/s]
Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.
We will change the batch size of 2 to the `num_generations` of 8
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 7,473 | Num Epochs = 1 | Total steps = 234
O^O/ \_/ \    Batch size per device = 32 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (32 x 8 x 1) = 256
 "-____-"     Trainable parameters = 35,192,832 of 529,225,600 (6.65% trained)
  0%|                                                                                                                                                | 0/234 [00:00<?, ?it/s]Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0, 'grad_norm': 1.8312383890151978, 'learning_rate': 1.8750000000000003e-06, 'num_tokens': 876251.0, 'completions/mean_length': 240.460546875, 'completions/min_length': 9.6, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.119140625, 'completions/mean_terminated_length': 204.47543334960938, 'completions/min_terminated_length': 9.6, 'completions/max_terminated_length': 503.0, 'rewards/strict_format_reward_func/mean': 0.0046875, 'rewards/strict_format_reward_func/std': 0.06028594672679901, 'rewards/isnumber_reward_func/mean': 0.001953125, 'rewards/isnumber_reward_func/std': 0.0217486210167408, 'rewards/soft_format_reward_func/mean': 0.0185546875, 'rewards/soft_format_reward_func/std': 0.1072581447660923, 'rewards/target_length_reward_func/mean': 0.0026661365604013555, 'rewards/target_length_reward_func/std': 0.03328094941971358, 'rewards/exact_match_reward_func/mean': 0.001171875, 'rewards/exact_match_reward_func/std': 0.01875, 'reward': 0.02903332430869341, 'reward_std': 0.07783851251006127, 'frac_reward_zero_std': 0.76875, 'completion_length': 240.460546875, 'kl': 2.1228855189292517e-05, 'epoch': 0.04}
{'loss': 0.0, 'grad_norm': 2.059141159057617, 'learning_rate': 3.958333333333333e-06, 'num_tokens': 1737440.0, 'completions/mean_length': 238.301953125, 'completions/min_length': 11.8, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.111328125, 'completions/mean_terminated_length': 204.82721862792968, 'completions/min_terminated_length': 11.8, 'completions/max_terminated_length': 502.9, 'rewards/strict_format_reward_func/mean': 0.012890625, 'rewards/strict_format_reward_func/std': 0.10994589328765869, 'rewards/isnumber_reward_func/mean': 0.00234375, 'rewards/isnumber_reward_func/std': 0.01887677013874054, 'rewards/soft_format_reward_func/mean': 0.0298828125, 'rewards/soft_format_reward_func/std': 0.14097051396965982, 'rewards/target_length_reward_func/mean': 0.011321232840418815, 'rewards/target_length_reward_func/std': 0.08642911277711392, 'rewards/exact_match_reward_func/mean': 0.001953125, 'rewards/exact_match_reward_func/std': 0.02328278198838234, 'reward': 0.058391544967889786, 'reward_std': 0.14343679025769235, 'frac_reward_zero_std': 0.715625, 'completion_length': 238.301953125, 'kl': 0.0009090749595998205, 'epoch': 0.09}
{'loss': 0.0, 'grad_norm': 3.7035021781921387, 'learning_rate': 4.993009492952951e-06, 'num_tokens': 2553804.0, 'completions/mean_length': 217.8171875, 'completions/min_length': 10.3, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.089453125, 'completions/mean_terminated_length': 189.20586090087892, 'completions/min_terminated_length': 10.3, 'completions/max_terminated_length': 505.7, 'rewards/strict_format_reward_func/mean': 0.064453125, 'rewards/strict_format_reward_func/std': 0.22871971055865287, 'rewards/isnumber_reward_func/mean': 0.008984375, 'rewards/isnumber_reward_func/std': 0.04446911141276359, 'rewards/soft_format_reward_func/mean': 0.116796875, 'rewards/soft_format_reward_func/std': 0.26338126361370084, 'rewards/target_length_reward_func/mean': 0.04781293710693717, 'rewards/target_length_reward_func/std': 0.1683504708111286, 'rewards/exact_match_reward_func/mean': 0.007421875, 'rewards/exact_match_reward_func/std': 0.07601354494690896, 'reward': 0.24546918496489525, 'reward_std': 0.4773493528366089, 'frac_reward_zero_std': 0.315625, 'completion_length': 217.8171875, 'kl': 0.022283326035540084, 'epoch': 0.13}
{'loss': 0.0001, 'grad_norm': 6.315835952758789, 'learning_rate': 4.9453690018345144e-06, 'num_tokens': 3269794.0, 'completions/mean_length': 180.78359375, 'completions/min_length': 8.9, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.0578125, 'completions/mean_terminated_length': 160.44847717285157, 'completions/min_terminated_length': 8.9, 'completions/max_terminated_length': 499.7, 'rewards/strict_format_reward_func/mean': 0.283984375, 'rewards/strict_format_reward_func/std': 0.44274730384349825, 'rewards/isnumber_reward_func/mean': 0.03671875, 'rewards/isnumber_reward_func/std': 0.08785994723439217, 'rewards/soft_format_reward_func/mean': 0.4255859375, 'rewards/soft_format_reward_func/std': 0.415828076004982, 'rewards/target_length_reward_func/mean': 0.20794768035411834, 'rewards/target_length_reward_func/std': 0.32569206058979033, 'rewards/exact_match_reward_func/mean': 0.0296875, 'rewards/exact_match_reward_func/std': 0.1581946924328804, 'reward': 0.983924263715744, 'reward_std': 1.0850022673606872, 'frac_reward_zero_std': 0.015625, 'completion_length': 180.78359375, 'kl': 0.09554161562118679, 'epoch': 0.17}
{'loss': 0.0002, 'grad_norm': 3.5257184505462646, 'learning_rate': 4.8405871765993435e-06, 'num_tokens': 3946890.0, 'completions/mean_length': 164.203125, 'completions/min_length': 17.1, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.029296875, 'completions/mean_terminated_length': 153.84481048583984, 'completions/min_terminated_length': 17.1, 'completions/max_terminated_length': 481.8, 'rewards/strict_format_reward_func/mean': 0.57734375, 'rewards/strict_format_reward_func/std': 0.4881860315799713, 'rewards/isnumber_reward_func/mean': 0.068359375, 'rewards/isnumber_reward_func/std': 0.11038061156868935, 'rewards/soft_format_reward_func/mean': 0.7197265625, 'rewards/soft_format_reward_func/std': 0.36429661214351655, 'rewards/target_length_reward_func/mean': 0.39856947064399717, 'rewards/target_length_reward_func/std': 0.36280728578567506, 'rewards/exact_match_reward_func/mean': 0.05703125, 'rewards/exact_match_reward_func/std': 0.21311624199151993, 'reward': 1.8210303783416748, 'reward_std': 1.1255862355232238, 'frac_reward_zero_std': 0.0, 'completion_length': 164.203125, 'kl': 0.1609580046031624, 'epoch': 0.21}
{'loss': 0.0016, 'grad_norm': 3.6919331550598145, 'learning_rate': 4.718964472511386e-06, 'num_tokens': 4634770.0, 'completions/mean_length': 160.815625, 'completions/min_length': 25.6, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.0234375, 'completions/mean_terminated_length': 152.6337142944336, 'completions/min_terminated_length': 25.6, 'completions/max_terminated_length': 472.5, 'rewards/strict_format_reward_func/mean': 0.78671875, 'rewards/strict_format_reward_func/std': 0.4053810566663742, 'rewards/isnumber_reward_func/mean': 0.0876953125, 'rewards/isnumber_reward_func/std': 0.11645998209714889, 'rewards/soft_format_reward_func/mean': 0.8740234375, 'rewards/soft_format_reward_func/std': 0.2620892733335495, 'rewards/target_length_reward_func/mean': 0.522039070725441, 'rewards/target_length_reward_func/std': 0.33150209188461305, 'rewards/exact_match_reward_func/mean': 0.062890625, 'rewards/exact_match_reward_func/std': 0.22140107229351996, 'reward': 2.333367204666138, 'reward_std': 0.8622381091117859, 'frac_reward_zero_std': 0.0, 'completion_length': 160.815625, 'kl': 1.571227255742997, 'epoch': 0.26}
{'loss': 0.001, 'grad_norm': 6.837715148925781, 'learning_rate': 4.522542485937369e-06, 'num_tokens': 5242316.0, 'completions/mean_length': 137.71015625, 'completions/min_length': 28.9, 'completions/max_length': 509.7, 'completions/clipped_ratio': 0.009375, 'completions/mean_terminated_length': 134.2014305114746, 'completions/min_terminated_length': 28.9, 'completions/max_terminated_length': 455.9, 'rewards/strict_format_reward_func/mean': 0.895703125, 'rewards/strict_format_reward_func/std': 0.30300107002258303, 'rewards/isnumber_reward_func/mean': 0.1095703125, 'rewards/isnumber_reward_func/std': 0.12121720910072327, 'rewards/soft_format_reward_func/mean': 0.9466796875, 'rewards/soft_format_reward_func/std': 0.1764273539185524, 'rewards/target_length_reward_func/mean': 0.5877860188484192, 'rewards/target_length_reward_func/std': 0.3046523928642273, 'rewards/exact_match_reward_func/mean': 0.091796875, 'rewards/exact_match_reward_func/std': 0.2795923948287964, 'reward': 2.631536030769348, 'reward_std': 0.6535275399684906, 'frac_reward_zero_std': 0.0, 'completion_length': 137.71015625, 'kl': 1.0214328427799046, 'epoch': 0.3}
{'loss': 0.0025, 'grad_norm': 3.1574866771698, 'learning_rate': 4.280940242378363e-06, 'num_tokens': 5832265.0, 'completions/mean_length': 130.311328125, 'completions/min_length': 31.1, 'completions/max_length': 497.2, 'completions/clipped_ratio': 0.008203125, 'completions/mean_terminated_length': 127.21185302734375, 'completions/min_terminated_length': 31.1, 'completions/max_terminated_length': 461.8, 'rewards/strict_format_reward_func/mean': 0.92890625, 'rewards/strict_format_reward_func/std': 0.25474728643894196, 'rewards/isnumber_reward_func/mean': 0.1390625, 'rewards/isnumber_reward_func/std': 0.12279550954699517, 'rewards/soft_format_reward_func/mean': 0.9654296875, 'rewards/soft_format_reward_func/std': 0.1504847936332226, 'rewards/target_length_reward_func/mean': 0.5870708703994751, 'rewards/target_length_reward_func/std': 0.30143962502479554, 'rewards/exact_match_reward_func/mean': 0.13203125, 'rewards/exact_match_reward_func/std': 0.3204121753573418, 'reward': 2.752500534057617, 'reward_std': 0.6054611921310424, 'frac_reward_zero_std': 0.0, 'completion_length': 130.311328125, 'kl': 2.5155538795515895, 'epoch': 0.34}
{'loss': 0.0023, 'grad_norm': 4.114614963531494, 'learning_rate': 3.999554736719785e-06, 'num_tokens': 6465543.0, 'completions/mean_length': 142.64921875, 'completions/min_length': 36.7, 'completions/max_length': 501.9, 'completions/clipped_ratio': 0.008203125, 'completions/mean_terminated_length': 139.62498474121094, 'completions/min_terminated_length': 36.7, 'completions/max_terminated_length': 442.4, 'rewards/strict_format_reward_func/mean': 0.9390625, 'rewards/strict_format_reward_func/std': 0.2372815191745758, 'rewards/isnumber_reward_func/mean': 0.15087890625, 'rewards/isnumber_reward_func/std': 0.11920334845781326, 'rewards/soft_format_reward_func/mean': 0.9669921875, 'rewards/soft_format_reward_func/std': 0.1487228162586689, 'rewards/target_length_reward_func/mean': 0.5923499643802643, 'rewards/target_length_reward_func/std': 0.29273282140493395, 'rewards/exact_match_reward_func/mean': 0.166796875, 'rewards/exact_match_reward_func/std': 0.36656629741191865, 'reward': 2.8160804510116577, 'reward_std': 0.5783570915460586, 'frac_reward_zero_std': 0.0, 'completion_length': 142.64921875, 'kl': 2.2857371248304843, 'epoch': 0.39}
{'loss': 0.0017, 'grad_norm': 3.950745105743408, 'learning_rate': 3.684671656182497e-06, 'num_tokens': 7087920.0, 'completions/mean_length': 142.653515625, 'completions/min_length': 31.2, 'completions/max_length': 480.5, 'completions/clipped_ratio': 0.009765625, 'completions/mean_terminated_length': 139.2363136291504, 'completions/min_terminated_length': 31.2, 'completions/max_terminated_length': 454.7, 'rewards/strict_format_reward_func/mean': 0.95625, 'rewards/strict_format_reward_func/std': 0.2033853679895401, 'rewards/isnumber_reward_func/mean': 0.1623046875, 'rewards/isnumber_reward_func/std': 0.11789468452334403, 'rewards/soft_format_reward_func/mean': 0.97734375, 'rewards/soft_format_reward_func/std': 0.12181939296424389, 'rewards/target_length_reward_func/mean': 0.5888598561286926, 'rewards/target_length_reward_func/std': 0.2927465125918388, 'rewards/exact_match_reward_func/mean': 0.15390625, 'rewards/exact_match_reward_func/std': 0.3413819044828415, 'reward': 2.8386645555496215, 'reward_std': 0.5349073886871338, 'frac_reward_zero_std': 0.0, 'completion_length': 142.653515625, 'kl': 1.672472715936601, 'epoch': 0.43}
{'loss': 0.0009, 'grad_norm': 4.232771873474121, 'learning_rate': 3.3433249684570757e-06, 'num_tokens': 7723613.0, 'completions/mean_length': 145.280078125, 'completions/min_length': 38.8, 'completions/max_length': 512.0, 'completions/clipped_ratio': 0.00625, 'completions/mean_terminated_length': 142.97894592285155, 'completions/min_terminated_length': 38.8, 'completions/max_terminated_length': 482.9, 'rewards/strict_format_reward_func/mean': 0.961328125, 'rewards/strict_format_reward_func/std': 0.19111041575670243, 'rewards/isnumber_reward_func/mean': 0.17626953125, 'rewards/isnumber_reward_func/std': 0.1121839813888073, 'rewards/soft_format_reward_func/mean': 0.9796875, 'rewards/soft_format_reward_func/std': 0.11655047237873077, 'rewards/target_length_reward_func/mean': 0.6391511201858521, 'rewards/target_length_reward_func/std': 0.278459358215332, 'rewards/exact_match_reward_func/mean': 0.16953125, 'rewards/exact_match_reward_func/std': 0.36993618607521056, 'reward': 2.925967478752136, 'reward_std': 0.5120039641857147, 'frac_reward_zero_std': 0.0, 'completion_length': 145.280078125, 'kl': 0.8990241272374988, 'epoch': 0.47}
{'loss': 0.0179, 'grad_norm': 3.437044620513916, 'learning_rate': 3.019779227044398e-06, 'num_tokens': 8354017.0, 'completions/mean_length': 141.4265625, 'completions/min_length': 37.5, 'completions/max_length': 483.3, 'completions/clipped_ratio': 0.0078125, 'completions/mean_terminated_length': 138.4918243408203, 'completions/min_terminated_length': 37.5, 'completions/max_terminated_length': 434.0, 'rewards/strict_format_reward_func/mean': 0.9578125, 'rewards/strict_format_reward_func/std': 0.194558846950531, 'rewards/isnumber_reward_func/mean': 0.17158203125, 'rewards/isnumber_reward_func/std': 0.11253963485360145, 'rewards/soft_format_reward_func/mean': 0.976953125, 'rewards/soft_format_reward_func/std': 0.12862476222217084, 'rewards/target_length_reward_func/mean': 0.6269918262958527, 'rewards/target_length_reward_func/std': 0.2956758141517639, 'rewards/exact_match_reward_func/mean': 0.168359375, 'rewards/exact_match_reward_func/std': 0.3550081178545952, 'reward': 2.9016988277435303, 'reward_std': 0.5402149617671966, 'frac_reward_zero_std': 0.0, 'completion_length': 141.4265625, 'kl': 17.879687779769302, 'epoch': 0.51}
{'loss': 0.0021, 'grad_norm': 5.505545616149902, 'learning_rate': 2.649510384862586e-06, 'num_tokens': 8958349.0, 'completions/mean_length': 134.6171875, 'completions/min_length': 39.8, 'completions/max_length': 499.5, 'completions/clipped_ratio': 0.00625, 'completions/mean_terminated_length': 132.26770248413087, 'completions/min_terminated_length': 39.8, 'completions/max_terminated_length': 440.4, 'rewards/strict_format_reward_func/mean': 0.970703125, 'rewards/strict_format_reward_func/std': 0.16408716887235641, 'rewards/isnumber_reward_func/mean': 0.17548828125, 'rewards/isnumber_reward_func/std': 0.10851123929023743, 'rewards/soft_format_reward_func/mean': 0.98515625, 'rewards/soft_format_reward_func/std': 0.10138115398585797, 'rewards/target_length_reward_func/mean': 0.6451492667198181, 'rewards/target_length_reward_func/std': 0.26905441135168073, 'rewards/exact_match_reward_func/mean': 0.196484375, 'rewards/exact_match_reward_func/std': 0.37636467814445496, 'reward': 2.972981357574463, 'reward_std': 0.485725000500679, 'frac_reward_zero_std': 0.0, 'completion_length': 134.6171875, 'kl': 2.112045038677752, 'epoch': 0.56}
{'loss': 0.0011, 'grad_norm': 3.690265655517578, 'learning_rate': 2.2759017277414165e-06, 'num_tokens': 9596442.0, 'completions/mean_length': 144.567578125, 'completions/min_length': 40.5, 'completions/max_length': 484.9, 'completions/clipped_ratio': 0.007421875, 'completions/mean_terminated_length': 141.89156036376954, 'completions/min_terminated_length': 40.5, 'completions/max_terminated_length': 446.2, 'rewards/strict_format_reward_func/mean': 0.975390625, 'rewards/strict_format_reward_func/std': 0.1499963730573654, 'rewards/isnumber_reward_func/mean': 0.17607421875, 'rewards/isnumber_reward_func/std': 0.1121058113873005, 'rewards/soft_format_reward_func/mean': 0.9859375, 'rewards/soft_format_reward_func/std': 0.0963721115142107, 'rewards/target_length_reward_func/mean': 0.6481695890426635, 'rewards/target_length_reward_func/std': 0.26661921888589857, 'rewards/exact_match_reward_func/mean': 0.17578125, 'rewards/exact_match_reward_func/std': 0.37695638835430145, 'reward': 2.9613531827926636, 'reward_std': 0.4753702014684677, 'frac_reward_zero_std': 0.0, 'completion_length': 144.567578125, 'kl': 1.115563939139247, 'epoch': 0.6}
{'loss': 0.0009, 'grad_norm': 3.57413387298584, 'learning_rate': 1.9072990557112567e-06, 'num_tokens': 10227262.0, 'completions/mean_length': 142.1640625, 'completions/min_length': 46.5, 'completions/max_length': 486.7, 'completions/clipped_ratio': 0.010546875, 'completions/mean_terminated_length': 138.25409927368165, 'completions/min_terminated_length': 46.5, 'completions/max_terminated_length': 442.9, 'rewards/strict_format_reward_func/mean': 0.96328125, 'rewards/strict_format_reward_func/std': 0.1831474483013153, 'rewards/isnumber_reward_func/mean': 0.199609375, 'rewards/isnumber_reward_func/std': 0.09763338342308998, 'rewards/soft_format_reward_func/mean': 0.980078125, 'rewards/soft_format_reward_func/std': 0.11850943937897682, 'rewards/target_length_reward_func/mean': 0.6614378571510315, 'rewards/target_length_reward_func/std': 0.2674388110637665, 'rewards/exact_match_reward_func/mean': 0.2140625, 'rewards/exact_match_reward_func/std': 0.39720348715782167, 'reward': 3.0184690952301025, 'reward_std': 0.5442731529474258, 'frac_reward_zero_std': 0.0, 'completion_length': 142.1640625, 'kl': 0.9354000948369503, 'epoch': 0.64}
{'loss': 0.0012, 'grad_norm': 7.213355541229248, 'learning_rate': 1.5519363433676794e-06, 'num_tokens': 10818519.0, 'completions/mean_length': 132.234765625, 'completions/min_length': 39.4, 'completions/max_length': 511.1, 'completions/clipped_ratio': 0.00859375, 'completions/mean_terminated_length': 128.96103210449218, 'completions/min_terminated_length': 39.4, 'completions/max_terminated_length': 440.2, 'rewards/strict_format_reward_func/mean': 0.961328125, 'rewards/strict_format_reward_func/std': 0.19102023392915726, 'rewards/isnumber_reward_func/mean': 0.20341796875, 'rewards/isnumber_reward_func/std': 0.09564841985702514, 'rewards/soft_format_reward_func/mean': 0.9783203125, 'rewards/soft_format_reward_func/std': 0.12403825223445893, 'rewards/target_length_reward_func/mean': 0.641459333896637, 'rewards/target_length_reward_func/std': 0.2792824894189835, 'rewards/exact_match_reward_func/mean': 0.225390625, 'rewards/exact_match_reward_func/std': 0.4098693788051605, 'reward': 3.009916400909424, 'reward_std': 0.5317297071218491, 'frac_reward_zero_std': 0.0, 'completion_length': 132.234765625, 'kl': 1.156951708905399, 'epoch': 0.68}
{'loss': 0.0028, 'grad_norm': 5.041938781738281, 'learning_rate': 1.217751806485235e-06, 'num_tokens': 11445251.0, 'completions/mean_length': 142.4296875, 'completions/min_length': 42.0, 'completions/max_length': 504.1, 'completions/clipped_ratio': 0.011328125, 'completions/mean_terminated_length': 138.29209747314454, 'completions/min_terminated_length': 42.0, 'completions/max_terminated_length': 463.8, 'rewards/strict_format_reward_func/mean': 0.964453125, 'rewards/strict_format_reward_func/std': 0.18118006736040115, 'rewards/isnumber_reward_func/mean': 0.20048828125, 'rewards/isnumber_reward_func/std': 0.0977346159517765, 'rewards/soft_format_reward_func/mean': 0.97890625, 'rewards/soft_format_reward_func/std': 0.1274348594248295, 'rewards/target_length_reward_func/mean': 0.6440537691116333, 'rewards/target_length_reward_func/std': 0.2732777088880539, 'rewards/exact_match_reward_func/mean': 0.19921875, 'rewards/exact_match_reward_func/std': 0.37293684631586077, 'reward': 2.9871201276779176, 'reward_std': 0.506958058476448, 'frac_reward_zero_std': 0.0, 'completion_length': 142.4296875, 'kl': 2.80984173361212, 'epoch': 0.73}
{'loss': 0.0079, 'grad_norm': 5.294959545135498, 'learning_rate': 9.412754953531664e-07, 'num_tokens': 12060741.0, 'completions/mean_length': 140.56328125, 'completions/min_length': 47.3, 'completions/max_length': 497.9, 'completions/clipped_ratio': 0.008203125, 'completions/mean_terminated_length': 137.51793518066407, 'completions/min_terminated_length': 47.3, 'completions/max_terminated_length': 448.0, 'rewards/strict_format_reward_func/mean': 0.9609375, 'rewards/strict_format_reward_func/std': 0.19150454550981522, 'rewards/isnumber_reward_func/mean': 0.2080078125, 'rewards/isnumber_reward_func/std': 0.09085057377815246, 'rewards/soft_format_reward_func/mean': 0.9787109375, 'rewards/soft_format_reward_func/std': 0.12220037654042244, 'rewards/target_length_reward_func/mean': 0.6297624111175537, 'rewards/target_length_reward_func/std': 0.2772128820419312, 'rewards/exact_match_reward_func/mean': 0.226171875, 'rewards/exact_match_reward_func/std': 0.4113480746746063, 'reward': 3.0035905122756956, 'reward_std': 0.5128482818603516, 'frac_reward_zero_std': 0.0, 'completion_length': 140.56328125, 'kl': 7.8888826508075, 'epoch': 0.77}
{'loss': 0.0019, 'grad_norm': 4.363409996032715, 'learning_rate': 6.673703204254348e-07, 'num_tokens': 12677225.0, 'completions/mean_length': 137.4640625, 'completions/min_length': 49.6, 'completions/max_length': 491.5, 'completions/clipped_ratio': 0.008984375, 'completions/mean_terminated_length': 134.0812973022461, 'completions/min_terminated_length': 49.6, 'completions/max_terminated_length': 400.0, 'rewards/strict_format_reward_func/mean': 0.970703125, 'rewards/strict_format_reward_func/std': 0.16622116640210152, 'rewards/isnumber_reward_func/mean': 0.203515625, 'rewards/isnumber_reward_func/std': 0.09591729417443276, 'rewards/soft_format_reward_func/mean': 0.980859375, 'rewards/soft_format_reward_func/std': 0.11649210266768932, 'rewards/target_length_reward_func/mean': 0.671094685792923, 'rewards/target_length_reward_func/std': 0.2612126678228378, 'rewards/exact_match_reward_func/mean': 0.20625, 'rewards/exact_match_reward_func/std': 0.3943083107471466, 'reward': 3.0324228286743162, 'reward_std': 0.4949065536260605, 'frac_reward_zero_std': 0.0, 'completion_length': 137.4640625, 'kl': 1.8786369392648339, 'epoch': 0.81}
{'loss': 0.0027, 'grad_norm': 5.700897216796875, 'learning_rate': 4.344030642100133e-07, 'num_tokens': 13295582.0, 'completions/mean_length': 138.183203125, 'completions/min_length': 42.5, 'completions/max_length': 465.1, 'completions/clipped_ratio': 0.009765625, 'completions/mean_terminated_length': 134.57291717529296, 'completions/min_terminated_length': 42.5, 'completions/max_terminated_length': 400.9, 'rewards/strict_format_reward_func/mean': 0.97421875, 'rewards/strict_format_reward_func/std': 0.15352525189518929, 'rewards/isnumber_reward_func/mean': 0.20205078125, 'rewards/isnumber_reward_func/std': 0.09662685990333557, 'rewards/soft_format_reward_func/mean': 0.98515625, 'rewards/soft_format_reward_func/std': 0.10166578441858291, 'rewards/target_length_reward_func/mean': 0.6764347732067109, 'rewards/target_length_reward_func/std': 0.2581535905599594, 'rewards/exact_match_reward_func/mean': 0.23125, 'rewards/exact_match_reward_func/std': 0.4009945422410965, 'reward': 3.0691105842590334, 'reward_std': 0.49937908053398133, 'frac_reward_zero_std': 0.0, 'completion_length': 138.183203125, 'kl': 2.7042734913527964, 'epoch': 0.86}
{'loss': 0.0023, 'grad_norm': 10.10975170135498, 'learning_rate': 2.4757783024395244e-07, 'num_tokens': 13895996.0, 'completions/mean_length': 132.82421875, 'completions/min_length': 39.1, 'completions/max_length': 447.5, 'completions/clipped_ratio': 0.00390625, 'completions/mean_terminated_length': 131.4553436279297, 'completions/min_terminated_length': 39.1, 'completions/max_terminated_length': 403.3, 'rewards/strict_format_reward_func/mean': 0.973828125, 'rewards/strict_format_reward_func/std': 0.1567137621343136, 'rewards/isnumber_reward_func/mean': 0.2140625, 'rewards/isnumber_reward_func/std': 0.08611998111009597, 'rewards/soft_format_reward_func/mean': 0.9865234375, 'rewards/soft_format_reward_func/std': 0.09377828463912011, 'rewards/target_length_reward_func/mean': 0.6839833378791809, 'rewards/target_length_reward_func/std': 0.23532463908195494, 'rewards/exact_match_reward_func/mean': 0.280078125, 'rewards/exact_match_reward_func/std': 0.43947877883911135, 'reward': 3.138475513458252, 'reward_std': 0.5053333193063736, 'frac_reward_zero_std': 0.0, 'completion_length': 132.82421875, 'kl': 2.27515171431005, 'epoch': 0.9}
{'loss': 0.0026, 'grad_norm': 12.348176956176758, 'learning_rate': 1.1106798553464804e-07, 'num_tokens': 14506579.0, 'completions/mean_length': 140.033984375, 'completions/min_length': 43.8, 'completions/max_length': 468.6, 'completions/clipped_ratio': 0.007421875, 'completions/mean_terminated_length': 137.31106262207032, 'completions/min_terminated_length': 43.8, 'completions/max_terminated_length': 414.1, 'rewards/strict_format_reward_func/mean': 0.967578125, 'rewards/strict_format_reward_func/std': 0.1720587320625782, 'rewards/isnumber_reward_func/mean': 0.2, 'rewards/isnumber_reward_func/std': 0.09859272763133049, 'rewards/soft_format_reward_func/mean': 0.982421875, 'rewards/soft_format_reward_func/std': 0.10768991522490978, 'rewards/target_length_reward_func/mean': 0.6609770357608795, 'rewards/target_length_reward_func/std': 0.2491161972284317, 'rewards/exact_match_reward_func/mean': 0.15859375, 'rewards/exact_match_reward_func/std': 0.35280735045671463, 'reward': 2.969570851325989, 'reward_std': 0.47084185779094695, 'frac_reward_zero_std': 0.0, 'completion_length': 140.033984375, 'kl': 2.5651114543899896, 'epoch': 0.94}
{'loss': 0.0038, 'grad_norm': 3.654761552810669, 'learning_rate': 2.7922934437178695e-08, 'num_tokens': 15110367.0, 'completions/mean_length': 133.3421875, 'completions/min_length': 51.3, 'completions/max_length': 432.2, 'completions/clipped_ratio': 0.006640625, 'completions/mean_terminated_length': 130.9370460510254, 'completions/min_terminated_length': 51.3, 'completions/max_terminated_length': 393.5, 'rewards/strict_format_reward_func/mean': 0.97734375, 'rewards/strict_format_reward_func/std': 0.14390234425663948, 'rewards/isnumber_reward_func/mean': 0.21328125, 'rewards/isnumber_reward_func/std': 0.08776912912726402, 'rewards/soft_format_reward_func/mean': 0.9884765625, 'rewards/soft_format_reward_func/std': 0.0893638014793396, 'rewards/target_length_reward_func/mean': 0.6649274706840516, 'rewards/target_length_reward_func/std': 0.25965574830770494, 'rewards/exact_match_reward_func/mean': 0.253515625, 'rewards/exact_match_reward_func/std': 0.4247810810804367, 'reward': 3.0975446701049805, 'reward_std': 0.5041083991527557, 'frac_reward_zero_std': 0.0, 'completion_length': 133.3421875, 'kl': 3.8267834344878793, 'epoch': 0.98}
{'train_runtime': 5726.7931, 'train_samples_per_second': 1.305, 'train_steps_per_second': 0.041, 'train_loss': 0.0027934881386870733, 'num_tokens': 15351892.0, 'completions/mean_length': 128.0205078125, 'completions/min_length': 43.75, 'completions/max_length': 478.75, 'completions/clipped_ratio': 0.001953125, 'completions/mean_terminated_length': 127.30976295471191, 'completions/min_terminated_length': 43.75, 'completions/max_terminated_length': 441.25, 'rewards/strict_format_reward_func/mean': 0.986328125, 'rewards/strict_format_reward_func/std': 0.1124197207391262, 'rewards/isnumber_reward_func/mean': 0.216796875, 'rewards/isnumber_reward_func/std': 0.07973803766071796, 'rewards/soft_format_reward_func/mean': 0.994140625, 'rewards/soft_format_reward_func/std': 0.05589779280126095, 'rewards/target_length_reward_func/mean': 0.6679105162620544, 'rewards/target_length_reward_func/std': 0.24737919494509697, 'rewards/exact_match_reward_func/mean': 0.2763671875, 'rewards/exact_match_reward_func/std': 0.44099855422973633, 'reward': 3.141543209552765, 'reward_std': 0.460783988237381, 'frac_reward_zero_std': 0.0, 'completion_length': 128.36495535714286, 'kl': 3.646593374865396, 'epoch': 1.0}

after GRPO: Accuracy -> 0.25018953752843065, Right format percent -> 0.9825625473843821